{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.13\n",
      "scikit-learn==1.4.2\n",
      "pandas==2.2.2\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "!pip freeze | grep scikit-learn\n",
    "!pip freeze | grep pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the model and the vectorizer\n",
    "with open('model.bin', 'rb') as f_in:\n",
    "    dv, model = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features\n",
    "categorical = ['PULocationID', 'DOLocationID']\n",
    "\n",
    "# read the data\n",
    "def read_data(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    df['duration'] = df.tpep_dropoff_datetime - df.tpep_pickup_datetime\n",
    "    df['duration'] = df.duration.dt.total_seconds() / 60\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)].copy()\n",
    "\n",
    "    df[categorical] = df[categorical].fillna(-1).astype('int').astype('str')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "year = str(2023).zfill(4)    \n",
    "month = str(3).zfill(2)\n",
    "\n",
    "# read the data\n",
    "df = read_data(f'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_{year}-{month}.parquet')\n",
    "\n",
    "# Predict the data\n",
    "dicts = df[categorical].to_dict(orient='records')\n",
    "X_val = dv.transform(dicts)\n",
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1: The standard deviation for predicted duration is 6.247488852238703\n"
     ]
    }
   ],
   "source": [
    "print(f'Q1: The standard deviation for predicted duration is {np.std(y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame()\n",
    "df_result['predicted_duration'] = y_pred\n",
    "df_result['ride_id'] = f'{year}/{month}_' + df.index.astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_parquet(\n",
    "    f'output_yellow_tripdata_{year}-{month}.parquet',\n",
    "    engine='pyarrow',\n",
    "    compression=None,\n",
    "    index=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q2: The size of the output file is 65.46 Megabytes\n"
     ]
    }
   ],
   "source": [
    "file_size = (os.path.getsize(f'output_yellow_tripdata_{year}-{month}.parquet')) / 1024 / 1024\n",
    "print(f\"Q2: The size of the output file is {file_size:.2f} Megabytes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q3: To convert the notebook into a script I used the command \n",
      "'jupyter nbconvert --to script nazmul_homework_4.ipynb --output script'\n"
     ]
    }
   ],
   "source": [
    "print(\"Q3: To convert the notebook into a script I used the command \\n'jupyter nbconvert --to script nazmul_homework_4.ipynb --output script'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q4: The first hash for Scikit-Learn is \n",
      "'sha256:1d0b25d9c651fd050555aadd57431b53d4cf664e749069da77f3d52c5ad14b3b'\n"
     ]
    }
   ],
   "source": [
    "print(\"Q4: The first hash for Scikit-Learn is \\n'sha256:1d0b25d9c651fd050555aadd57431b53d4cf664e749069da77f3d52c5ad14b3b'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q5: The mean predicted duration is 14.292282936862449\n"
     ]
    }
   ],
   "source": [
    "!python script.py 2023 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q6: The mean predicted duration is 0.19174419265916945\n"
     ]
    }
   ],
   "source": [
    "!docker run batch-docker-script:1.3 2023 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
